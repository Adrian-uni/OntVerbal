{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"zXKOIhMDbGIX","outputId":"ecc71cc2-bd87-4b16-f00c-59abef7fb459","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install transformers\n!pip install datasets\n!pip install gdown","metadata":{"id":"JhYY2aLBEAWy","outputId":"8bea556f-1e51-485a-ce3d-36ca78a0252f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#download from drive verb_onto_data.zip and unzip\n\n#verbalizaciones base\n!gdown '1zKe_gbx-45Wl5pdwk8a5dI9icY38j1-l' \n!unzip verb_onto_data.zip\n\n#verbalizaciones formal\n#!gdown '1Dn40nCe29inYqseRcfjCXqzX_mQcL23Y' \n#!unzip verb_onto_data_formal.zip\n\n#verbalizaciones simple\n#!gdown '1oVLc490hPmGzktvgdcxvzONqubgF1llF' \n#!unzip verb_onto_data_simple.zip","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **ENTRENAR BERT: OBJETIVO MÁSCARA**\n\n- Descargar tokenizer y modelo\n- Leer línea a línea del fichero de texto\n- Codificar y enmascarar fichero con verbalizaciones\n- Entrenar y guardar modelo entrenado\n","metadata":{"id":"keoY52SxEHBd"}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForMaskedLM\nfrom transformers import DataCollatorForLanguageModeling\nfrom transformers import TrainingArguments, Trainer\nfrom datasets import load_dataset\nimport numpy as np\nimport re\nimport os\n","metadata":{"id":"qsHqTtDKFCCp","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = 'bert-base-uncased' \n#model_name = 'bert-large-uncased-whole-word-masking'\n#model_name = 'roberta-base'\n#model_name = 'roberta-large'\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForMaskedLM.from_pretrained(model_name)","metadata":{"id":"DSgPKOPAkBGv","outputId":"1b36bd0e-093c-4db5-eff7-9ea28a2a020b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndata = load_dataset('text', data_files = ['./*.txt'])","metadata":{"id":"C263F5OcMOci","outputId":"331360eb-036e-41a5-8945-0cac56fd49e0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"id":"YLVgJr7xmyUf","outputId":"f9eb0a60-873e-4d6c-9c8a-c50abc1ece8a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_function(rows):\n    inputs = tokenizer(re.sub(\"_\", \" \", rows['text']), truncation=True)\n    return inputs","metadata":{"id":"wUW5z9S6RB5U","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_data = data.map(preprocess_function)","metadata":{"id":"yIIMVd5URJHI","outputId":"9e8147bf-84b1-444c-ccd3-d2e7af2a9df6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_collator_mlm = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n)","metadata":{"id":"ZaRyNhMCYbYi","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nbatch_size = 8\ntotal_epochs_train = 4\n\nargs_train = TrainingArguments(\n    output_dir='my_checkpoints', #directorio salida\n    overwrite_output_dir=True, #para empezar de nuevo cada vez, no tenemos mucho espacio\n    evaluation_strategy=\"no\", # no queremos evaluacion\n    save_strategy=\"epoch\", #indicamos que si queremos guardar el modelo, cada vez que se hace una pasada por todos los datos se guarda el modelo para guardar los pesos\n    per_device_train_batch_size=batch_size, #cuauntos datos vamos a usar para entrenar\n    per_device_eval_batch_size=batch_size*2, #realmente no afecta porque hemos indicado que no evaluamos\n    optim=\"adamw_torch\", #optimizador que se usa en la red neuronal para encontrar el minimo\n    learning_rate=2e-5, # 1e-5\n    weight_decay=0.01, # no cambiar\n    warmup_ratio=0.1,# 0.0\n    logging_steps=100,\n    load_best_model_at_end=False,\n    num_train_epochs=total_epochs_train, # numoer de veces que queremos pasr por todos los ratos( cada vez se denomina \"epoca\"), en este caso hay 3 epocas\n    report_to='all', \n    save_total_limit = 1, # cauntos modelos queremos guardar, con esto siempre nos quedamos con el ultimo, si no lo ponemos se guardaran todos los modelos\n    )\n\ntrainer = Trainer(\n    model=model,\n    args=args_train,\n    data_collator=data_collator_mlm, #prepara los datos para que BERT use la mascara\n    train_dataset=encoded_data['train'],\n    eval_dataset=None,\n    tokenizer=tokenizer,\n)\n# Train the model\ntrainer.train()","metadata":{"id":"uh5gJUsaRS8T","outputId":"30680d44-183a-4191-e30e-71da4ad35912","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **FINE-TUNING: CLASIFICAR**\n\n- Cargar el modelo para clasificar secuencias\n- Hacer fine-tuning con datos de entrenamiento\n- Clasificar datos de test y calcular f1","metadata":{"id":"-BnYvIKojlNM"}},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\nfrom datasets import load_dataset, load_metric\nimport re\nimport os\nfrom sklearn.metrics import confusion_matrix, classification_report\ndel model\ndel trainer","metadata":{"id":"4KV3XjrHj8t0","outputId":"a82194ea-8d51-4a1c-bbd9-07d06322b589","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!gdown '1nf5loPW7MhcJA4g48Pt2xmLMwXWuoH-T'\n!unzip tripletaCSV_1.zip\n\n#!gdown '1i1WNaRAtKmQI4QTXvGk7DUiVTnWH3euO'\n#!unzip tripletaCSV_2.zip\n\n#!gdown '1sJMWhzPjApRZmHBE-Qu1Khsb4Iu9Zle3'\n#!unzip tripletaCSV_3.zip\n\n#!gdown '1AaS5ll2jtFFIH7z1BMcCnMUDyb74qc7H'\n#!unzip tripletaCSV_4.zip\n\n#!gdown '1QyOjErHCU8iC6T5wm9mGC9VTCoZpkNgD'\n#!unzip tripletaCSV_5.zip","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_class = load_dataset('csv', data_files={'train':['train.csv'], 'val': ['val.csv'], 'test':['test.csv']})\ndata_class","metadata":{"id":"1_ABYwE_nJ_Z","outputId":"1816d38b-98cc-4c10-ae58-10e83730933b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def verb_row(row, template, tokenizer):\n    w1 = re.sub(\"_\", \" \", str(row['source']))\n    w2 = re.sub(\"_\", \" \", str(row['target']))\n    label=int(row['rel'])\n    sentence = re.sub(\"<W1>\", w1, template)\n    sentence = re.sub(\"<W2>\", w2, sentence)\n    sentence = re.sub(\"<SEP>\", tokenizer.sep_token, sentence)\n    return {'text':sentence, 'labels':label}","metadata":{"id":"J51AxU-GnMSg","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"template = \"'<W1>' <SEP> '<W2>'\"\ndata_class_v = data_class.map(verb_row, \n                   fn_kwargs={'template':template, 'tokenizer':tokenizer}, \n                   remove_columns=['rel','source','target'])\ndata_class_v","metadata":{"id":"WrQEho9AnOj4","outputId":"77cb4b4c-59ad-4291-92c7-13c36db64534","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_class_v['train'][0]","metadata":{"id":"P6K6GQs5zA5j","outputId":"e53f86a6-7e05-473b-9a34-ce20cd47d537","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_data_class = data_class_v.map(preprocess_function, remove_columns=['text'])\nencoded_data_class","metadata":{"id":"WTfdgHVinQ3Z","outputId":"39c5ed17-795d-4b2f-a9d9-56d3dca675fe","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_dir = os.listdir(args_train.output_dir)\nlist_dir.sort()\ntrained_model_checkpoint = args_train.output_dir + \"/\" + list_dir[0]\n","metadata":{"id":"SlfbNDfBnTOQ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    '''\nCompute metrics for a Trainer.\n\nArgs:\n  eval_pred: object of type transformers.EvalPrediction. It is a tuple with \n  predictions (logits) and real labels.\n\nReturns:\n  A dictionary of metrics {'name_metric1':value1,...}\n'''\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis = 1)\n    return metric.compute(predictions=predictions, references=labels)","metadata":{"id":"TkrxUdhJoOjR","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_data_class['train'][0:2]","metadata":{"id":"lIXDG4jUA_DI","outputId":"5e29c935-e3c3-4433-9d1c-bdbbaf49521f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from random import randint\nTOTAL = 10\nseeds = [randint(1,100) for i in range(TOTAL)]\nwhile len(seeds) != len(set(seeds)):\n    seeds = [randint(1,100) for i in range(TOTAL)]\n\nmetric_name = \"f1\"\nmetric = load_metric(metric_name)\nbatch_size = 8\ntotal_epochs = 3\n\nprecision_verb = []\nprecision_no_verb = []\nrecall_verb = []\nrecall_no_verb = []\nf1_verb = []\nf1_no_verb = []\nfor i in range(TOTAL):\n    model_class = AutoModelForSequenceClassification.from_pretrained(trained_model_checkpoint, num_labels=2)\n    seed = seeds[i]\n\n    args_train_class = TrainingArguments(\n        output_dir='my_checkpoints_class',\n        overwrite_output_dir=True,\n        evaluation_strategy=\"epoch\", \n        save_strategy=\"epoch\",\n        per_device_train_batch_size=batch_size,\n        per_device_eval_batch_size=batch_size*2,\n        optim=\"adamw_torch\",\n        learning_rate=2e-5,\n        weight_decay=0.01,\n        warmup_ratio=0.1,\n        logging_steps=100,\n        load_best_model_at_end=True,\n        num_train_epochs=total_epochs,\n        metric_for_best_model=metric_name,\n        seed=seed,\n        report_to='all',\n        save_total_limit = 3,\n        )\n\n    trainer = Trainer(\n        model=model_class,\n        args=args_train_class,\n        train_dataset=encoded_data_class['train'],\n        eval_dataset=encoded_data_class['val'],\n        tokenizer=tokenizer,\n        compute_metrics=compute_metrics\n        )\n\n    # Train the mode\n    trainer.train()\n\n    predicciones = trainer.predict(test_dataset=encoded_data_class['test'])\n\n    #calculate the predicted labels 0/1 based on the field predictions of the object predicciones\n    #predicciones.predictions contains the logits\n    pred = np.argmax(predicciones.predictions, axis = 1)\n    f1_verb.append(metric.compute(predictions=pred, references=predicciones.label_ids)['f1'])\n    results_acc = (classification_report(predicciones.label_ids, pred, digits=4, output_dict=True))\n    precision_verb.append(results_acc['1']['precision'])\n    recall_verb.append(results_acc['1']['recall'])\n    print(metric.compute(predictions=pred, references=predicciones.label_ids))\n    print(confusion_matrix(predicciones.label_ids,y_pred =pred))\n\n\n    model_class_bert = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n    args_train_class_bert = TrainingArguments(\n        output_dir='my_checkpoints_class_bert',\n        overwrite_output_dir=True,\n        evaluation_strategy=\"epoch\", \n        save_strategy=\"epoch\",\n        per_device_train_batch_size=batch_size,\n        per_device_eval_batch_size=batch_size*2,\n        optim=\"adamw_torch\",\n        learning_rate=2e-5,\n        weight_decay=0.01,\n        warmup_ratio=0.1,\n        logging_steps=100,\n        load_best_model_at_end=True,\n        num_train_epochs=total_epochs,\n        metric_for_best_model=metric_name,\n        seed=seed,\n        report_to='all',\n        save_total_limit = 3,\n        )\n\n    trainer_bert = Trainer(\n        model=model_class_bert,\n        args=args_train_class_bert,\n        train_dataset=encoded_data_class['train'],\n        eval_dataset=encoded_data_class['val'],\n        tokenizer=tokenizer,\n        compute_metrics=compute_metrics\n        )\n\n    # Train the model\n    trainer_bert.train()\n\n    predicciones = trainer_bert.predict(test_dataset=encoded_data_class['test'])\n\n    #calculate the predicted labels 0/1 based on the field predictions of the object predicciones\n    #predicciones.predictions contains the logits\n    pred = np.argmax(predicciones.predictions, axis = 1)\n    f1_no_verb.append(metric.compute(predictions=pred, references=predicciones.label_ids)['f1'])\n    results_acc = (classification_report(predicciones.label_ids, pred, digits=4, output_dict=True))\n    precision_no_verb.append(results_acc['1']['precision'])\n    recall_no_verb.append(results_acc['1']['recall'])\n    print(metric.compute(predictions=pred, references=predicciones.label_ids))\n    print(confusion_matrix(predicciones.label_ids,y_pred =pred))\n    print('iteracion numero ' + str(i) )","metadata":{"id":"_oyO7DEGl9kR","outputId":"3bd4f1ce-a2fd-4ec1-cf78-a3825e4f5a59","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.mean(f1_verb))\nprint(np.mean(f1_no_verb))","metadata":{"id":"mMc-4RSAog7y","outputId":"a395eec5-6ae7-4cfc-f5d1-712344200bb0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.std(f1_verb))\nprint(np.std(f1_no_verb))","metadata":{"id":"FlVItTUW1OMs","outputId":"0179c7e5-41f1-4a42-d63b-2ba47c67bc27","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statistics import mean\n\nf = open('results_datasets_1.tsv', 'w')\nfor i in range(TOTAL):\n    f.write(str(i) + '\\t' + model_name + '\\t' + str(total_epochs_train) + '\\t' + str(total_epochs) + \n            '\\t' +\"datasets_1\" + '\\t' + 'formal' + '\\t' +  'CON_VERB' + \n            '\\t' + str(precision_verb[i]) + '\\t' + str(recall_verb[i]) + '\\t' + str(f1_verb[i]) + '\\n')\n    f.write(str(i) + '\\t' + model_name + '\\t' + str(total_epochs_train) + '\\t' + str(total_epochs) + \n            '\\t' +\"datasets_1\" + '\\t' + 'formal' + '\\t' +  'SIN_VERB' + \n            '\\t' + str(precision_no_verb[i]) + '\\t' + str(recall_no_verb[i]) + '\\t' + str(f1_no_verb[i]) + '\\n\\n')\nf.write('Media total: ' + '\\t' +  'CON_VERB' + '\\t' +  str(mean(precision_verb)) + '\\t' + str(mean(recall_verb)) + '\\t' + str(mean(f1_verb)) + '\\n')\nf.write('Media total: ' + '\\t' +  'SIN_VERB' + '\\t' +  str(mean(precision_no_verb)) + '\\t' + str(mean(recall_no_verb)) + '\\t' + str(mean(f1_no_verb)) + '\\n')\nf.close()","metadata":{"id":"5HVgrgbF57dg","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **BUCLE GRANDE AUTOMATIZAR**","metadata":{}},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n\n!pip install transformers\n!pip install datasets\n!pip install gdown\n\nfrom transformers import AutoTokenizer, AutoModelForMaskedLM\nfrom transformers import DataCollatorForLanguageModeling\nfrom transformers import TrainingArguments, Trainer\nfrom datasets import load_dataset\nimport numpy as np\nimport re\nimport os\n\nfrom transformers import AutoModelForSequenceClassification\nfrom datasets import load_dataset, load_metric\nimport re\nimport os\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom random import randint\nfrom statistics import mean\n","metadata":{"execution":{"iopub.status.busy":"2022-06-19T20:46:27.302933Z","iopub.execute_input":"2022-06-19T20:46:27.303415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def verb_row(row, template, tokenizer):\n    w1 = re.sub(\"_\", \" \", str(row['source']))\n    w2 = re.sub(\"_\", \" \", str(row['target']))\n    label=int(row['rel'])\n    sentence = re.sub(\"<W1>\", w1, template)\n    sentence = re.sub(\"<W2>\", w2, sentence)\n    sentence = re.sub(\"<SEP>\", tokenizer.sep_token, sentence)\n    return {'text':sentence, 'labels':label}\n\ndef compute_metrics(eval_pred):\n    '''\nCompute metrics for a Trainer.\n​\nArgs:\n  eval_pred: object of type transformers.EvalPrediction. It is a tuple with \n  predictions (logits) and real labels.\n​\nReturns:\n  A dictionary of metrics {'name_metric1':value1,...}\n'''\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis = 1)\n    return metric.compute(predictions=predictions, references=labels)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **DATOS**","metadata":{}},{"cell_type":"code","source":"tiposVerbalizacion = ['base', 'formal', 'simple' ]\n\n#verbalizaciones base\n#tipoVerbalizacion = 'base'\n!gdown '1zKe_gbx-45Wl5pdwk8a5dI9icY38j1-l' \n\n\n#verbalizaciones formal\n#tipoVerbalizacion = 'formal'\n!gdown '1Dn40nCe29inYqseRcfjCXqzX_mQcL23Y' \n\n\n#verbalizaciones simple\n#tipoVerbalizacion = 'simple'\n!gdown '1oVLc490hPmGzktvgdcxvzONqubgF1llF' \n\ndef getVerbalizaciones(verbalizacion):\n    if verbalizacion == 'base':\n        !unzip -o verb_onto_data.zip\n    if verbalizacion == 'formal':\n        !unzip -o verb_onto_data_formal.zip\n    if verbalizacion == 'simple':\n        !unzip -o verb_onto_data_simple.zip\n\n\ntiposModelos = ['bert-large', 'roberta-base', 'roberta-large']\n    \n#model_name = 'bert-base-uncased' \n#model_name = 'bert-large-uncased-whole-word-masking'\n#model_name = 'roberta-base'\n#model_name = 'roberta-large'\n\n\ntripletas = ['tripleta1', 'tripleta2', 'tripleta3', 'tripleta4', 'tripleta5']\n!gdown '1nf5loPW7MhcJA4g48Pt2xmLMwXWuoH-T'\n!gdown '1i1WNaRAtKmQI4QTXvGk7DUiVTnWH3euO'\n!gdown '1sJMWhzPjApRZmHBE-Qu1Khsb4Iu9Zle3'\n!gdown '1AaS5ll2jtFFIH7z1BMcCnMUDyb74qc7H'\n!gdown '1QyOjErHCU8iC6T5wm9mGC9VTCoZpkNgD'\n\ndef getTripletaCSV(tripleta):\n    \n    if tripleta == 'tripleta1':\n        !unzip -o tripletaCSV_1.zip\n\n    if tripleta == 'tripleta2':\n        !unzip -o tripletaCSV_2.zip\n\n    if tripleta == 'tripleta3':  \n        !unzip -o tripletaCSV_3.zip\n\n    if tripleta == 'tripleta4':\n        !unzip -o tripletaCSV_4.zip\n\n    if tripleta == 'tripleta5':\n        !unzip -o tripletaCSV_5.zip\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.rmtree(\"/kaggle/working/my_checkpoints_class\")\nshutil.rmtree(\"/kaggle/working/my_checkpoints\")\nshutil.rmtree(\"/kaggle/working/my_checkpoints_class_bert\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\ntipoTripleta = 1\ngetTripletaCSV(tripletas[0])\nfor modelo in tiposModelos:\n    model_name = modelo\n    for verbalizacion in tiposVerbalizacion:\n        getVerbalizaciones(verbalizacion)\n        \n        numEpocas = 3\n\n        tokenizer = AutoTokenizer.from_pretrained(model_name)\n        model = AutoModelForMaskedLM.from_pretrained(model_name)\n\n        data = load_dataset('text', data_files = ['./*.txt'])\n\n        def preprocess_function(rows):\n            inputs = tokenizer(re.sub(\"_\", \" \", rows['text']), truncation=True)\n            return inputs\n\n        encoded_data = data.map(preprocess_function)\n\n        data_collator_mlm = DataCollatorForLanguageModeling(\n            tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n        )\n\n\n\n\n\n\n\n        # Entrenamiento 1\n\n        batch_size = 8\n        total_epochs_train = numEpocas\n        args_train = TrainingArguments(\n            output_dir='my_checkpoints', #directorio salida\n            overwrite_output_dir=True, #para empezar de nuevo cada vez, no tenemos mucho espacio\n            evaluation_strategy=\"no\", # no queremos evaluacion\n            save_strategy=\"epoch\", #indicamos que si queremos guardar el modelo, cada vez que se hace una pasada por todos los datos se guarda el modelo para guardar los pesos\n            per_device_train_batch_size=batch_size, #cuauntos datos vamos a usar para entrenar\n            per_device_eval_batch_size=batch_size*2, #realmente no afecta porque hemos indicado que no evaluamos\n            optim=\"adamw_torch\", #optimizador que se usa en la red neuronal para encontrar el minimo\n            learning_rate=2e-5, # 1e-5\n            weight_decay=0.01, # no cambiar\n            warmup_ratio=0.1,# 0.0\n            logging_steps=100,\n            load_best_model_at_end=False,\n            num_train_epochs=total_epochs_train, # numoer de veces que queremos pasr por todos los ratos( cada vez se denomina \"epoca\"), en este caso hay 3 epocas\n            report_to='all', \n            save_total_limit = 1, # cauntos modelos queremos guardar, con esto siempre nos quedamos con el ultimo, si no lo ponemos se guardaran todos los modelos\n            )\n        trainer = Trainer(\n            model=model,\n            args=args_train,\n            data_collator=data_collator_mlm, #prepara los datos para que BERT use la mascara\n            train_dataset=encoded_data['train'],\n            eval_dataset=None,\n            tokenizer=tokenizer,\n        )\n        # Train the model\n        trainer.train()\n\n\n\n\n\n\n\n\n\n\n\n\n        del model\n        del trainer\n\n        data_class = load_dataset('csv', data_files={'train':['train.csv'], 'val': ['val.csv'], 'test':['test.csv']})\n\n\n        template = \"'<W1>' <SEP> '<W2>'\"\n        data_class_v = data_class.map(verb_row, \n                           fn_kwargs={'template':template, 'tokenizer':tokenizer}, \n                           remove_columns=['rel','source','target'])\n\n        encoded_data_class = data_class_v.map(preprocess_function, remove_columns=['text'])\n\n        list_dir = os.listdir(args_train.output_dir)\n        list_dir.sort()\n        trained_model_checkpoint = args_train.output_dir + \"/\" + list_dir[0]\n\n\n\n\n\n\n\n\n\n\n\n        # Entrenamiento 2\n\n        TOTAL = 10\n        seeds = [randint(1,100) for i in range(TOTAL)]\n        while len(seeds) != len(set(seeds)):\n            seeds = [randint(1,100) for i in range(TOTAL)]\n        metric_name = \"f1\"\n        metric = load_metric(metric_name)\n        batch_size = 8\n        total_epochs = 3\n        precision_verb = []\n        precision_no_verb = []\n        recall_verb = []\n        recall_no_verb = []\n        f1_verb = []\n        f1_no_verb = []\n        for i in range(TOTAL):\n            model_class = AutoModelForSequenceClassification.from_pretrained(trained_model_checkpoint, num_labels=2)\n            seed = seeds[i]\n            args_train_class = TrainingArguments(\n                output_dir='my_checkpoints_class',\n                overwrite_output_dir=True,\n                evaluation_strategy=\"epoch\", \n                save_strategy=\"epoch\",\n                per_device_train_batch_size=batch_size,\n                per_device_eval_batch_size=batch_size*2,\n                optim=\"adamw_torch\",\n                learning_rate=2e-5,\n                weight_decay=0.01,\n                warmup_ratio=0.1,\n                logging_steps=100,\n                load_best_model_at_end=True,\n                num_train_epochs=total_epochs,\n                metric_for_best_model=metric_name,\n                seed=seed,\n                report_to='all',\n                save_total_limit = 3,\n                )\n            trainer = Trainer(\n                model=model_class,\n                args=args_train_class,\n                train_dataset=encoded_data_class['train'],\n                eval_dataset=encoded_data_class['val'],\n                tokenizer=tokenizer,\n                compute_metrics=compute_metrics\n                )\n            # Train the mode\n            trainer.train()\n            predicciones = trainer.predict(test_dataset=encoded_data_class['test'])\n            #calculate the predicted labels 0/1 based on the field predictions of the object predicciones\n            #predicciones.predictions contains the logits\n            pred = np.argmax(predicciones.predictions, axis = 1)\n            f1_verb.append(metric.compute(predictions=pred, references=predicciones.label_ids)['f1'])\n            results_acc = (classification_report(predicciones.label_ids, pred, digits=4, output_dict=True))\n            precision_verb.append(results_acc['1']['precision'])\n            recall_verb.append(results_acc['1']['recall'])\n            print(metric.compute(predictions=pred, references=predicciones.label_ids))\n            print(confusion_matrix(predicciones.label_ids,y_pred =pred))\n            model_class_bert = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n            args_train_class_bert = TrainingArguments(\n                output_dir='my_checkpoints_class_bert',\n                overwrite_output_dir=True,\n                evaluation_strategy=\"epoch\", \n                save_strategy=\"epoch\",\n                per_device_train_batch_size=batch_size,\n                per_device_eval_batch_size=batch_size*2,\n                optim=\"adamw_torch\",\n                learning_rate=2e-5,\n                weight_decay=0.01,\n                warmup_ratio=0.1,\n                logging_steps=100,\n                load_best_model_at_end=True,\n                num_train_epochs=total_epochs,\n                metric_for_best_model=metric_name,\n                seed=seed,\n                report_to='all',\n                save_total_limit = 3,\n                )\n\n            trainer_bert = Trainer(\n                model=model_class_bert,\n                args=args_train_class_bert,\n                train_dataset=encoded_data_class['train'],\n                eval_dataset=encoded_data_class['val'],\n                tokenizer=tokenizer,\n                compute_metrics=compute_metrics\n                )\n\n            # Train the model\n            trainer_bert.train()\n\n            predicciones = trainer_bert.predict(test_dataset=encoded_data_class['test'])\n\n            #calculate the predicted labels 0/1 based on the field predictions of the object predicciones\n            #predicciones.predictions contains the logits\n            pred = np.argmax(predicciones.predictions, axis = 1)\n            f1_no_verb.append(metric.compute(predictions=pred, references=predicciones.label_ids)['f1'])\n            results_acc = (classification_report(predicciones.label_ids, pred, digits=4, output_dict=True))\n            precision_no_verb.append(results_acc['1']['precision'])\n            recall_no_verb.append(results_acc['1']['recall'])\n            print(metric.compute(predictions=pred, references=predicciones.label_ids))\n            print(confusion_matrix(predicciones.label_ids,y_pred =pred))\n            print('iteracion numero ' + str(i) )\n\n        f = open( 'results_' + str(model_name) + '_' + str(numEpocas) + '_' + str(verbalizacion) + '_' + str(tipoTripleta) + '.tsv', 'w')\n        for i in range(TOTAL):\n            f.write(str(i) + '\\t' + model_name + '\\t' + str(total_epochs_train) + '\\t' + str(total_epochs) + \n                    '\\t' +\"datasets_1\" + '\\t' + 'formal' + '\\t' +  'CON_VERB' + \n                    '\\t' + str(precision_verb[i]) + '\\t' + str(recall_verb[i]) + '\\t' + str(f1_verb[i]) + '\\n')\n            f.write(str(i) + '\\t' + model_name + '\\t' + str(total_epochs_train) + '\\t' + str(total_epochs) + \n                    '\\t' +\"datasets_1\" + '\\t' + 'formal' + '\\t' +  'SIN_VERB' + \n                    '\\t' + str(precision_no_verb[i]) + '\\t' + str(recall_no_verb[i]) + '\\t' + str(f1_no_verb[i]) + '\\n\\n')\n        f.write('Media total: ' + '\\t' +  'CON_VERB' + '\\t' +  str(mean(precision_verb)) + '\\t' + str(mean(recall_verb)) + '\\t' + str(mean(f1_verb)) + '\\n')\n        f.write('Media total: ' + '\\t' +  'SIN_VERB' + '\\t' +  str(mean(precision_no_verb)) + '\\t' + str(mean(recall_no_verb)) + '\\t' + str(mean(f1_no_verb)) + '\\n')\n        f.close()\n        \n        shutil.rmtree(\"/kaggle/working/my_checkpoints_class\")\n        shutil.rmtree(\"/kaggle/working/my_checkpoints\")\n        shutil.rmtree(\"/kaggle/working/my_checkpoints_class_bert\")\n        \n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}